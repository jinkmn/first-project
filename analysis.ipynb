{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d741ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b4eb8",
   "metadata": {},
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9539d4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2996 entries, 0 to 2995\n",
      "Data columns (total 22 columns):\n",
      " #   Column                                                                  Non-Null Count  Dtype \n",
      "---  ------                                                                  --------------  ----- \n",
      " 0   申込区分                                                                    2996 non-null   object\n",
      " 1   申込区分（日本語）                                                               2996 non-null   object\n",
      " 2   ロール                                                                     2996 non-null   object\n",
      " 3   本日の総合的な満足度を５段階で教えてください。                                                 2996 non-null   int64 \n",
      " 4   本日の講義内容について５段階で教えてください。 \n",
      "学習量は適切だった                                      2996 non-null   int64 \n",
      " 5   本日の講義内容について５段階で教えてください。 \n",
      "講義内容が十分に理解できた                                  2996 non-null   int64 \n",
      " 6   本日の講義内容について５段階で教えてください。 \n",
      "運営側のアナウンスが適切だった                                2996 non-null   int64 \n",
      " 7   本日の講師の総合的な満足度を５段階で教えてください。                                              2996 non-null   int64 \n",
      " 8   本日の講師について５段階で教えてください。\n",
      "授業時間を効率的に使っていた                                    2996 non-null   int64 \n",
      " 9   本日の講師について５段階で教えてください。\n",
      "質問に丁寧に対応してくれた                                     2996 non-null   int64 \n",
      " 10  本日の講師について５段階で教えてください。\n",
      "話し方や声の大きさが適切だった                                   2996 non-null   int64 \n",
      " 11  ご自身について５段階で教えてください。\n",
      "事前に予習をした                                            2996 non-null   int64 \n",
      " 12  ご自身について５段階で教えてください。\n",
      "意欲をもって講義に臨んだ                                        2996 non-null   int64 \n",
      " 13  ご自身について５段階で教えてください。\n",
      "今回学んだことを学習や研究に生かせる                                  2996 non-null   int64 \n",
      " 14  親しいご友人にこの講義の受講をお薦めしますか？                                                 2996 non-null   int64 \n",
      " 15  【必須】本日の講義で学んだことを50文字以上で入力してください。                                        2996 non-null   object\n",
      " 16  （任意）本日の講義で特によかった部分について、具体的にお教えください。                                     875 non-null    object\n",
      " 17  （任意）分かりにくかった部分や改善点などがあれば、具体的にお教えください。                                   435 non-null    object\n",
      " 18  （任意）講師について、よかった点や不満があった点などについて、具体的にお教えください。                             371 non-null    object\n",
      " 19  （任意）今後開講してほしい講義・分野などがあればお書きください。                                        375 non-null    object\n",
      " 20  （任意）ご自由にご意見をお書きください。                                                    388 non-null    object\n",
      " 21  (任意) 今回がテスト運用となるチャットbotですが、今後改善をしていきたいと思います。気になる点、改善要望等あればぜひFBをお願いします。  227 non-null    object\n",
      "dtypes: int64(12), object(10)\n",
      "memory usage: 515.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"Day1_アンケート .xlsx\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dff8ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['申込区分', '申込区分（日本語）', 'ロール', '本日の総合的な満足度を５段階で教えてください。 ',\n",
       "       '本日の講義内容について５段階で教えてください。 \\n学習量は適切だった',\n",
       "       '本日の講義内容について５段階で教えてください。 \\n講義内容が十分に理解できた',\n",
       "       '本日の講義内容について５段階で教えてください。 \\n運営側のアナウンスが適切だった',\n",
       "       '本日の講師の総合的な満足度を５段階で教えてください。', '本日の講師について５段階で教えてください。\\n授業時間を効率的に使っていた',\n",
       "       '本日の講師について５段階で教えてください。\\n質問に丁寧に対応してくれた',\n",
       "       '本日の講師について５段階で教えてください。\\n話し方や声の大きさが適切だった',\n",
       "       'ご自身について５段階で教えてください。\\n事前に予習をした', 'ご自身について５段階で教えてください。\\n意欲をもって講義に臨んだ',\n",
       "       'ご自身について５段階で教えてください。\\n今回学んだことを学習や研究に生かせる', '親しいご友人にこの講義の受講をお薦めしますか？',\n",
       "       '【必須】本日の講義で学んだことを50文字以上で入力してください。',\n",
       "       '（任意）本日の講義で特によかった部分について、具体的にお教えください。',\n",
       "       '（任意）分かりにくかった部分や改善点などがあれば、具体的にお教えください。',\n",
       "       '（任意）講師について、よかった点や不満があった点などについて、具体的にお教えください。',\n",
       "       '（任意）今後開講してほしい講義・分野などがあればお書きください。', '（任意）ご自由にご意見をお書きください。',\n",
       "       '(任意) 今回がテスト運用となるチャットbotですが、今後改善をしていきたいと思います。気になる点、改善要望等あればぜひFBをお願いします。'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a5ea80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>不明</td>\n",
       "      <td>student</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>並列で学習させる際の種類について</td>\n",
       "      <td>半導体の話がおもしろそうだと思えたこと</td>\n",
       "      <td>OmniCampusにZoomのリンクを載せる動線では駄目でしょうか？_毎回、動線が散漫とし...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>松尾研がどのような研究をされているのか知りたいです。</td>\n",
       "      <td>昨年資料にもありましたが、第１回目で各回の紹介は要らないように思います。</td>\n",
       "      <td>ぜひ英語表記を併記してほしいです！日本語表記になると訳文だとわかる日本語になってしまい、本当...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>不明</td>\n",
       "      <td>student</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>主に大規模言語モデル(LLM)の概要や講義の前半について学びました。LLMは単語列の生成確率...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>不明</td>\n",
       "      <td>student</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>大規模言語モデルの概要、今後学んでいくことの概要を認識できた。</td>\n",
       "      <td>今後の講義を外観できた。</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>初学者のため、理解は薄いと思いますが、今後の講義の全体感をつかめました。引き続き、よろしくお...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>学生</td>\n",
       "      <td>student</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>LLMの大まかな構造とこれからやっていくこと、LLM が世間ではどのように実装され実践的に活...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPONSOR</td>\n",
       "      <td>会員企業</td>\n",
       "      <td>student</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>・講座概要\\n・LLMの概要\\n　└次の文字列を確率的に計算しているモデルである\\n　└これ...</td>\n",
       "      <td>A先生の講義</td>\n",
       "      <td>各回の概要について。全体像を掴めたのは良かったが、1時間超かけてやるべきかは議論の余地がある...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>見逃しているだけだと思うが、講義内容は知識としての内容が多い印象なので、実際のアプリケーショ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1     2        3   4   5   6   7   8   9   10  ...  13  14  15  \\\n",
       "0      OTHER    不明  student   2   3   3   2   2   4   2  ...   3   1   5   \n",
       "1      OTHER    不明  student   2   2   2   2   1   1   3  ...   4   3   3   \n",
       "2      OTHER    不明  student   2   3   3   3   3   4   3  ...   4   2   5   \n",
       "3  EDUCATION    学生  student   2   4   4   2   2   3   4  ...   4   5   7   \n",
       "4    SPONSOR  会員企業  student   2   2   3   3   3   3   3  ...   2   2   2   \n",
       "\n",
       "                                                  16                   17  \\\n",
       "0                                   並列で学習させる際の種類について  半導体の話がおもしろそうだと思えたこと   \n",
       "1  主に大規模言語モデル(LLM)の概要や講義の前半について学びました。LLMは単語列の生成確率...                  NaN   \n",
       "2                    大規模言語モデルの概要、今後学んでいくことの概要を認識できた。         今後の講義を外観できた。   \n",
       "3  LLMの大まかな構造とこれからやっていくこと、LLM が世間ではどのように実装され実践的に活...                  NaN   \n",
       "4  ・講座概要\\n・LLMの概要\\n　└次の文字列を確率的に計算しているモデルである\\n　└これ...               A先生の講義   \n",
       "\n",
       "                                                  18   19  \\\n",
       "0  OmniCampusにZoomのリンクを載せる動線では駄目でしょうか？_毎回、動線が散漫とし...  NaN   \n",
       "1                                                NaN  NaN   \n",
       "2                                                NaN  NaN   \n",
       "3                                                NaN  NaN   \n",
       "4  各回の概要について。全体像を掴めたのは良かったが、1時間超かけてやるべきかは議論の余地がある...  NaN   \n",
       "\n",
       "                                                  20  \\\n",
       "0                         松尾研がどのような研究をされているのか知りたいです。   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  見逃しているだけだと思うが、講義内容は知識としての内容が多い印象なので、実際のアプリケーショ...   \n",
       "\n",
       "                                                  21  \\\n",
       "0               昨年資料にもありましたが、第１回目で各回の紹介は要らないように思います。   \n",
       "1                                                NaN   \n",
       "2  初学者のため、理解は薄いと思いますが、今後の講義の全体感をつかめました。引き続き、よろしくお...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                  22  \n",
       "0  ぜひ英語表記を併記してほしいです！日本語表記になると訳文だとわかる日本語になってしまい、本当...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = range(1,df.shape[1]+1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e7776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_columns = 17\n",
    "negative_columns = 18\n",
    "positive = df.loc[df[positive_columns].notnull(),positive_columns].to_list()\n",
    "negative = df.loc[df[positive_columns].notnull(),negative_columns].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c2753",
   "metadata": {},
   "source": [
    "# geminiのAPIキーを用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fab06c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40022ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36fb5fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = positive[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660fc736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 分析結果の例 ---\n",
      "{\n",
      "  \"classifications\": [\n",
      "    {\n",
      "      \"comment_index\": 0,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 1,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 2,\n",
      "      \"sentiment\": 2,\n",
      "      \"topic\": 3\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 3,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 4,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 5,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 6,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 7,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 8,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 9,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 1\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 10,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 3\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 11,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 12,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 2\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 13,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 14,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 2\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 15,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 16,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 17,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 18,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 19,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 20,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 21,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 22,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 23,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 24,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 25,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 26,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 27,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 28,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 29,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 30,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 31,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 32,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 33,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 34,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 35,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 36,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 1\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 37,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 38,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 39,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 40,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 41,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 42,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 43,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 44,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 45,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 46,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 47,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 48,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 49,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 50,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 51,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 52,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 53,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 54,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 55,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 56,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 57,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 58,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 59,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 60,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 61,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 62,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 63,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 64,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 65,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 66,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 67,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 68,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 69,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 70,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 71,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 72,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 73,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 74,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 75,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 76,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 77,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 5\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 78,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 79,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    },\n",
      "    {\n",
      "      \"comment_index\": 80,\n",
      "      \"sentiment\": 0,\n",
      "      \"topic\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"important_comments\": [\n",
      "    22,\n",
      "    28,\n",
      "    39,\n",
      "    45,\n",
      "    51,\n",
      "    60,\n",
      "    70,\n",
      "    72,\n",
      "    79\n",
      "  ],\n",
      "  \"dangerous_comments\": []\n",
      "}\n",
      "positive comments:['半導体の話がおもしろそうだと思えたこと', '今後の講義を外観できた。', '単語列の生成確率のモデル化、これを基本としてモデルを育てているのがイメージしやすくて良かった。', 'どんな講義を受けていくのかについて理解ができた', 'コースの各回の概略を知ることができた。', 'NN やBERTあたりで止まっている私のAI知識をアップデートする深い内容だったと思います。LLMってAIの最前線なんですね。', '導入のお話でわかりやすかった', 'llmを開発するための具体的な計算資源等への言及があったのが良かった。', '日本で開発している言語モデルがGPT-4などと比較してどの程度の規模なのかについてよく知らなかったので\\\\nイメージしやすいスライドがあったのがよかったです。', 'Bさんの講座。資料の流れが分かりやすく、講座の全体像が掴みやすかったです。', '来週以降への期待。', '初めて講座を受講したため、講座の基本的な枠組み、全体的な概要を説明いただいたことは親切であると感じました。', '初回というのも有り、全体として細部には踏み込みすぎず、理解し易い構成になっていたと感じます。', '運営の事前の資料や説明が非常にわかりやすく、全く混乱なく当日を迎えられたことが素晴らしかった。講義の内容も、易しすぎず難しすぎず、初回としては良い導入だったと思う。アーカイブの公開も迅速で、受講時間の調整がしやすいので大変有難い。無償ということが信じられない。', '全体像の解説がされていた点。', 'LLMの学習にリソースが足りない場合の対処方法に興味があるので、並列化の方法の講義を楽しみにしています。', 'LLMの現状の概観を掴めて良かった。', '「日本のLLMを取り巻く環境」で日本の開発状況を知れたことがよかった。', 'モデルをスケールして学習させる場合、データ並列以外にも、モデル並列と呼ばれる手法があることが分かり、複数のGPUがあるならば、うまく活用することで効率的に学習させることができるということを知ることができた', 'LLMの基盤モデルと言う考え方がなぜパラダイムシフトになっているのかといったことがわかってよかった。(LLM以降に機械学習を触った人間なので当たり前だと思っていたが、歴史を知ることでなぜこれが次のブームになっているのかをしれた)', '体系的にLLMの動向が分かって良かったです。', '言語モデルの定義から入ったことで、概論的な技術感や戦略、展望に着いていくことができた。', 'あまり予習をしていなかったため、概要を聞けてよかったです。', '内容が入門的だった為、概論と各項目の関係を理解しやすかった', '日本LLMの現状について教えてもらえたのがよかったです。', 'LLMの活用法（PromptingとRAG）', 'どんな難しい、専門的な話が展開されるか心配していましたが、初歩的な説明や配慮が感じられ、嬉しかった。もちろん、これからハイレベルな講義になっていくと思うので、油断はできないのですが。', '前年からLLMを取り巻く環境も変わり、それを踏まえて講座を前年からアップデートしてもらえていることにこれからの期待感が高まりました。', '今の開発の現状が知れたこと。', 'RAGについてあいまいな理解しかなかったのですが、スライド1枚で非常にわかりやすくまとまっていたものがあって勉強になりました。\\\\nまた、半導体についての話や、今後の講義で分野特化のLLMやロボットへの応用方法についても学べるということで楽しみになりました。', '大規模モデルの具体的なパラメータ数や日本のGPUリソースの整備状況などについても解説があり，世界と日本との具体的な差分がよくわかった．', 'これからの授業で話す内容の言葉の意味や概要を軽く知ることができて、興味がさらに湧きました。', '前回のLLMの講座は受講していませんが、今回は日程も長く内容も盛り沢山ということで、多くのことが学べる予感がしています。全体概要の説明でその点を知ることができたのは今後の参考になりました。', 'Tanukiの紹介が結構なされていたところ。\\\\n初学者に向けてうまく今後の授業日程と絡めて、全体像を説明されていたところ。', '例で紹介されていた行動系列の生成についてはロボットのできることが増えていることと、純粋に面白いなと思いました。', '各回の解説だけでも、一部知らなかったような話がいくつもあり、今後の講義が楽しみになりました。', '図が豊富でこれまで学んだことも復習ができました。', '事前に資料が共有されてよかったです。', '全体像を説明されたので、理解の助けになりそうと感じた。', '第一回目とということで各回の概要について簡単に触れていただいた点です。これにより、全体の概要の理解と今後の授業のモチベーション向上に繋がりました。', '全講義の概要を説明してくれたので、見通しが良いと思った。', '最終課題のコンペについて知れたこと、講義全体の構成を知れたことは良かったです。', '・スケール則自体やその経済的意味について初めて知れたので、良かったです。', 'LLMに至るまでの歴史的な変遷は知らなかったのでためになった。', 'LLMをなぜやる必要があるのかを冒頭に説明してもらえたことがよかった。今後のモチベーションに繋がった。', 'Transformer登場までの概要を知れたのがよかった。\\\\nまた、各回の概要についても事前に触れておくことができたため、受講時の理解度が深まりそう。', '今後の学習ロードマップをとおして自分が予習が必要な箇所を認識できた点が非常によかったです。\\\\n', 'LLMの基本的な内容から説明くださり、関連知識がおさらいできて良かった。', '汎用LLMの事前学習に計算機資源がどの程度必要なのか知ることができて大変興味深かったです。', 'よく出てくるが理解していなかったグラフや用語を理解できた。\\u3000日本と米国の進捗状態、勝つための方策＝”新しいものは性能が伸びる、消費電力が下がる、なので今ここで力を入れれば巻き返せる。”\\u3000ピンと来たのですが、他国も圧倒的な量のGPUを使って研究開発をするので他国にもできるかなと思うところがあります。まず、遅れないこと、国策としての日本語LLMを強くできればと思いいます。またフォロワーに徹して、ファインチューニング部分でいろんなドメインで勝つことが大事で、企業ユースなど付加価値は、ファインチューニング部分のほうが応用上は70％～80％になるような世界になれば、ファンダメンタルモデルをつく津琴乃後れを取り返せる。そのような戦略とビジョンで国全体で動くことがより現実的と思われます。\\\\n', '限られた時間で私のような全くの素人に対しても、前述の原理や使用されている技術、公開されているLLMの現状と今後新たなLLMを開発する上での問題点等を俯瞰できるようによく練られた構成だと感じました。', '先に各講義の概要が聞けたので、本応用講座の内容についてイメージつきやすくなった。', '全体像を把握できました。', 'NN、FineTuning、Promptingの比較', '学習データ、モデル、コンピュータリソースのスケールさせることがLLMの性能向上には重要という内容が印象的でした。', '難しい計算式がありつつも、ある程度抽象化した表現で、LLMがどういう仕組み、原理になっているのか説明が非常に分かりやすかった', 'モデルの学習に必要な計算量が概算できるというを知れたのはよかった。\\\\n', 'LLM の概要については、これまでにも耳にする機会があったが、具体的なグラフや数値でデータを示してくれた点がよかった。', '起源の部分に関しての学習ができてよかったです。', '講義を通じて、LLMの構造について具体的なイメージができたことで、これがどのように世界で必要とされ続ける技術であるかをより理解できました。特に、LLMが単なる言語処理だけでなく、様々な分野で応用可能な汎用性を持つことや、スケーラビリティによって解決できるタスクの幅が広がっていることが印象的でした。\\\\n\\\\nまた、TransformerのSelf-Attention機構が、言語の文脈を深く理解し、より正確な出力を可能にしている点も、LLMが他の技術とは一線を画す理由として納得できました。これらの理解を通じて、LLMがただの技術に留まらず、将来にわたって世界中で様々な問題解決に寄与し続ける存在であることを強く実感しました。', '講義のプレビューといった内容で、次回以降が楽しみになりました。', '初心者でも体系的に学べそうだと言う点がよかったです。', 'それぞれの講義の概要をしれたことと、日本のLLM環境を把握できたことです。\\\\n後者については、自分の知識がアップデートできました。', 'なるべく難しい言葉を使わず、分かりやすい表現でご説明されようとしていたことが伝わり、努力次第で確かな知識・スキルの習得ができるという期待感を持てたことがありがたかったです。', 'LLMがこれまでの深層学習手法とどれくらい異なっているものなのか（モデルは同一でプロンプトでタスクの指定が可能）を理解することができた', '言語モデルからの説明をして頂いたのが良かった', '全体の内容と学習する内容のレベル感がつかめた。', '昨年度からのアップデート部分の説明を聞き、今後の学習モチベーションが高まりました。\\\\nアップデート部分がこの1年でのLLMにおける着目すべきポイントであったり重要なポイントであると思いますので、昨年度の資料との違いについても着目しながら受講しようと思います。', '全体的に資料が見やすく、文字だけではなく優しい言葉で説明されておりましたので非常にわかりやすかったです。', '言語モデルなどでは具体的な例を挙げて説明して頂いたので理解が容易だった。', 'それぞれのスライドの内容が簡潔にまとめられていて、わかりやすかったです。', 'これからの回の概要を前もって共有いただけたのはモチベーション的な意味でもよいと感じました。\\\\n半導体の回は普通にLLMの勉強をしているだけではインプットされない分野でもあるので、楽しみにしています。', '今後の講義内容のサマリーが参考になりました。', '各回で大規模言語モデルにおけるどのようなことを学んでいくのかを、目次紹介のような形で共有いただき、全体像が把握できた点。これにより、これからの各回のインプットの質が高まると思われます。', '講座の各回の概要を解説があったので、今後の学習の流れが具体的にイメージできてよかった。\\\\nますます学習意欲が高まりました。', 'どういったことを学習するのか全体像を把握することができたこと。', 'llm研究開発の日本の現状について、まとまって知れたのが良かったです。特に、日本は英語圏に比べて遅れながらも、この1年ぐらいは結構頑張っている感じがしました。', 'まず第1回がLLMの歴史的背景・巨大化する意味とそれに伴う法則・技術の概要・世界の状況と日本の立ち位置についてざっくり全体を俯瞰することができる回なのが良かったと思います。スライドも見やすく、説明もわかりやすかったです。今後の講義の流れをイメージしながら聴くことができました。', '分かりやすくご説明いただき大変有難かったです。', '説明がすごく分かりやすかったです。']\n",
      "important_commnts:['言語モデルの定義から入ったことで、概論的な技術感や戦略、展望に着いていくことができた。', '前年からLLMを取り巻く環境も変わり、それを踏まえて講座を前年からアップデートしてもらえていることにこれからの期待感が高まりました。', '全体像を説明されたので、理解の助けになりそうと感じた。', 'LLMをなぜやる必要があるのかを冒頭に説明してもらえたことがよかった。今後のモチベーションに繋がった。', '限られた時間で私のような全くの素人に対しても、前述の原理や使用されている技術、公開されているLLMの現状と今後新たなLLMを開発する上での問題点等を俯瞰できるようによく練られた構成だと感じました。', '講義を通じて、LLMの構造について具体的なイメージができたことで、これがどのように世界で必要とされ続ける技術であるかをより理解できました。特に、LLMが単なる言語処理だけでなく、様々な分野で応用可能な汎用性を持つことや、スケーラビリティによって解決できるタスクの幅が広がっていることが印象的でした。\\\\n\\\\nまた、TransformerのSelf-Attention機構が、言語の文脈を深く理解し、より正確な出力を可能にしている点も、LLMが他の技術とは一線を画す理由として納得できました。これらの理解を通じて、LLMがただの技術に留まらず、将来にわたって世界中で様々な問題解決に寄与し続ける存在であることを強く実感しました。', '言語モデルなどでは具体的な例を挙げて説明して頂いたので理解が容易だった。', 'これからの回の概要を前もって共有いただけたのはモチベーション的な意味でもよいと感じました。\\\\n半導体の回は普通にLLMの勉強をしているだけではインプットされない分野でもあるので、楽しみにしています。', '分かりやすくご説明いただき大変有難かったです。']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=api_key) \n",
    "model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "\n",
    "def classify_comments_batch_simple(comments: list[str] | pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    複数のコメントをバッチ処理で感情分析し、\n",
    "    結果をシンプルなJSONオブジェクト（Pythonでは辞書）で返す関数。\n",
    "    \"\"\"\n",
    "    if not isinstance(comments, list):\n",
    "        comments = comments.to_list()\n",
    "\n",
    "    if not comments:\n",
    "        print(\"分析対象のコメントがありません。\")\n",
    "        return None\n",
    "    \n",
    "    # プロンプトのテンプレート\n",
    "    prompt_template = \"\"\"\n",
    "あなたは、講義アンケートのコメントを分析する専門のアナリストです。\n",
    "これからJSON形式で渡されるコメントのリストを分析し、以下のルールに従って結果を一つのJSONオブジェクトとして出力してください。\n",
    "\n",
    "# 全体のルール\n",
    "- あなたの応答は、解説や前置きなしに、指定されたJSONフォーマットのコードブロックのみにしてください。\n",
    "- 入力されたコメントのインデックス番号は0から始まります。\n",
    "\n",
    "# 分類ルール\n",
    "各コメントに対して、以下の2つの分類を行ってください。\n",
    "1.  **sentiment**: コメントの感情を分析し、以下のいずれかの数値を割り当ててください。\n",
    "    - `0`: ポジティブ\n",
    "    - `1`: ネガティブ\n",
    "    - `2`: どちらでもない\n",
    "2.  **topic**: コメントが何についての言及か、以下のカテゴリに分類してください。\n",
    "    - `0`: 講義内容について\n",
    "    - `1`: 講義資料について\n",
    "    - `2`: 運営について\n",
    "    - `3`: 講師について\n",
    "    - `4`:チャットボットについて\n",
    "    - `5`:その他\n",
    "\n",
    "# 重要コメントの抽出ルール\n",
    "コメント全体をレビューし、以下の基準の**いずれか1つ以上に合致する**コメントを「重要コメント」と判断し、そのインデックス番号（0から始まる番号）をリストにまとめてください。\n",
    "- 複数回（目安として3回以上）言及されている共通の改善点が含まれている。\n",
    "- 緊急の対応が必要と思われる内容（例：システム障害、重大な誤り）が含まれている。\n",
    "- 具体的な改善案が含まれている。\n",
    "\n",
    "# 危険コメントの抽出ルール\n",
    "コメント全体をレビューし、以下の基準に合致するコメントのインデックス番号を特定し、リストに追加してください。\n",
    "- **dangerous**: 誹謗中傷、人格攻撃、違法行為を示唆するような不適切な内容を含むコメントのインデックス。\n",
    "\n",
    "# 出力フォーマット\n",
    "以下のJSON構造を厳守してください。\"important_comments\"と\"dangerous_comments\"の値は、インデックス番号の配列（リスト）です。\n",
    "\n",
    "{\n",
    "  \"classifications\": [\n",
    "    {\n",
    "      \"comment_index\": 0,\n",
    "      \"sentiment\": 0,\n",
    "      \"topic\": \"1\"\n",
    "    },\n",
    "    {\n",
    "      \"comment_index\": 1,\n",
    "      \"sentiment\": 1,\n",
    "      \"topic\": \"3\"\n",
    "    }\n",
    "  ],\n",
    "  \"important_comments\": [15, 22, 28],\n",
    "  \"dangerous_comments\": [45]\n",
    "}\n",
    "\n",
    "---\n",
    "それでは、以下のコメントリストを分析してください。\n",
    "\n",
    "【入力コメントリスト】\n",
    "\"\"\"\n",
    "\n",
    "    comment_list_str = json.dumps(comments, ensure_ascii=False)\n",
    "    prompt = prompt_template + comment_list_str\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        clean_response = response.text.strip().replace('```json', '').replace('```', '').strip()\n",
    "        analysis_result = json.loads(clean_response)\n",
    "        return analysis_result\n",
    "    except Exception as e:\n",
    "        print(f\"エラーが発生しました: {e}\")\n",
    "        # print(\"APIからの応答:\", response.text) # デバッグ用に残しておくと便利\n",
    "        return None\n",
    "\n",
    "# このコードを実行するには、ご自身のAPIキーをセットしてください\n",
    "results = classify_comments_batch_simple(comments)\n",
    "positive_comments = []\n",
    "positive_counts = 0\n",
    "negative_comments = []\n",
    "negative_counts = 0\n",
    "topic_counts = {}\n",
    "important_comments = []\n",
    "dengerous_comments = []\n",
    "\n",
    "\n",
    "if results and 'classifications' in results:\n",
    "    for classification in results['classifications']:\n",
    "        # sentimentの値と、元のコメントのインデックス番号を取得\n",
    "        sentiment = classification['sentiment']\n",
    "        topic = classification['topic']\n",
    "        comment_index = classification['comment_index']\n",
    "        \n",
    "        # 元のコメントを取得\n",
    "        original_comment = comments[comment_index]\n",
    "\n",
    "        # sentimentの値に応じて、各リストにコメントを追加\n",
    "        if sentiment == 0:  # 0はポジティブ\n",
    "            positive_comments.append(original_comment)\n",
    "        elif sentiment == 1:  # 1はネガティブ\n",
    "            negative_comments.append(original_comment)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        topic_counts[topic] = topic_counts.get(topic, 0) + 1\n",
    "\n",
    "if results and 'important_comments' in results:\n",
    "    for i in results['important_comments']:\n",
    "        important_comments.append(comments[i])\n",
    "\n",
    "if results and 'dengerous_comments' in results:\n",
    "    for i in results['dengerous_comments']:\n",
    "        dengerous_comments.append(comments[i])\n",
    "\n",
    "\n",
    "    \n",
    "print(\"--- 分析結果の例 ---\")\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))\n",
    "print(f'positive comments:{positive_comments}')\n",
    "# print(f'negative comments:{negative_comments}')\n",
    "print(f'important_commnts:{important_comments}')\n",
    "# print(f'dengerous_comments:{dengerous_comments}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4e71f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'topics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m topics \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'topics'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "020fe8da",
   "metadata": {},
   "source": [
    "コメント数が多いと出力上限ではじかれる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05892b1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef95ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
